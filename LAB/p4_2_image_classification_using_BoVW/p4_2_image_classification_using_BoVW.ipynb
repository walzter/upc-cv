{"cells":[{"cell_type":"markdown","metadata":{"id":"Sk0eYw8ojrFq"},"source":["# Laboratory #4_2 : Image Classification using Bag of Visual Words\n","\n","At the end of this laboratory, you would get familiarized with\n","\n","*   Creating Bag of Visual Words\n","    *   Feature Extraction\n","    *   Codebook construction\n","    *   Classification\n","*   Using pre-trained deep networks for feature extraction\n","\n","**Remember this is a graded exercise.**\n","\n","*   For every plot, make sure you provide appropriate titles, axis labels, legends, wherever applicable.\n","*   Create reusable functions where ever possible, so that the code could be reused at different places.\n","*   Mount your drive to access the images.\n","*   Add sufficient comments and explanations wherever necessary.\n","\n","---"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sYHw1lSBldl-"},"outputs":[],"source":["#from google.colab import drive\n","#drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"aD5-E8PuaQ5P"},"outputs":[],"source":["# Loading necessary libraries (Feel free to add new libraries if you need for any computation)\n","import os\n","import numpy as np\n","from sklearn.cluster import MiniBatchKMeans\n","from sklearn.preprocessing import StandardScaler\n","from skimage.color import rgb2gray\n","from skimage.io import imread\n","from skimage import feature\n","from scipy.cluster.vq import vq\n","import glob\n","from matplotlib import pyplot as plt\n","import cv2\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n"]},{"cell_type":"markdown","metadata":{"id":"ampx9DIJiuGN"},"source":["## Loading dataset\n","\n","We will use 3 categories from Caltech 101 objects dataset for this experiment. Upload the dataset to the drive and mount it."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"PRSJP1XbG6-a"},"outputs":[],"source":["# modify the dataset variable with the path from your drive\n","dataset_path = '/Users/Eric/Documents/Uni/Msc/Courses/Sem1/CV/LAB/p4_2_image_classification_using_BoVW/101_ObjectCategories'"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"fNoe7u755X6Q"},"outputs":[],"source":["categories = ['butterfly', 'kangaroo', 'dalmatian']\n","ncl = len(categories) * 10"]},{"cell_type":"markdown","metadata":{"id":"gxY0mDoK5EQj"},"source":["*   Create a list of file and the corresponding labels"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"EQptvDX5AFem"},"outputs":[],"source":["#solution\n","def get_fn_label(listoffiles):\n","    fn_label = []\n","    for category in listoffiles:\n","        #list of the corresponing files \n","        all_files = glob.glob(dataset_path + '/' + category +'/*.jpg')\n","        for x in all_files: \n","            fn_label.append((x,category))\n","    return fn_label"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"3x42veHz5LDt"},"outputs":[{"name":"stdout","output_type":"stream","text":["Total number of images: 244\n"]}],"source":["data = get_fn_label(categories)\n","print('Total number of images:', len(data))"]},{"cell_type":"markdown","metadata":{"id":"XgVhdjYz5Zhs"},"source":["*   Create a train / test split where the test is 10% of the total data"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Train set: 219\n","Test set: 25\n"]}],"source":["# solution\n","df = pd.DataFrame(data)\n","df.columns = ['fn','label']\n","X = df.drop('label',axis=1)\n","y = df.drop('fn',axis=1)\n","#splitting\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42)\n","#check\n","print('Train set:', len(X_train))\n","print('Test set:', len(X_test))"]},{"cell_type":"markdown","metadata":{"id":"_Hl36Ej_5k6Y"},"source":["*   How do you select the train/test split?"]},{"cell_type":"markdown","metadata":{"id":"-aOe27Kx5vtd"},"source":["**Solution**\n","\n","By using the \"test_size\" parameter of the train_test_split function from sklearn.model_selection, we chose the test_size and the training is complementary to the test_size. "]},{"cell_type":"markdown","metadata":{"id":"18OZf2kfkVNB"},"source":["## Feature Extraction using ORB\n","\n","The first step is to extract descriptors for each image in our dataset. We will use ORB to extract descriptors.\n","\n","*   Create ORB detector with 256 keypoints.\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"ptLbPcoow-ar"},"outputs":[],"source":["# solution\n","descriptor_extractor = feature.ORB(n_keypoints=256)"]},{"cell_type":"markdown","metadata":{"id":"3yinPkL8brow"},"source":["*   Extract ORB descriptors from all the images in the train set.\n"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"PCiXJeLFxGtP"},"outputs":[],"source":["# solution\n","def all_to_gray(image): \n","  try: \n","    image_gray = rgb2gray(cv2.cvtColor(image, cv2.COLOR_RGBA2RGB))\n","  except Exception as e:\n","    image_gray = rgb2gray(image)\n","  return image_gray\n","#####################################################\n","\n","def get_ORB(image1,n_keypoints_ = 256):\n","  IMAGE1_GRAY = all_to_gray(image1)\n","  #instantiate the ORB\n","  DescExt = feature.ORB(n_keypoints = n_keypoints_)\n","  #Detect and Extract features for image 1\n","  DescExt.detect_and_extract(IMAGE1_GRAY)\n","  kpts = DescExt.keypoints\n","  descr = DescExt.descriptors\n","  return descr\n","\n","# Much faster ORB feature\n","def cv2_ORB(image, keypoints=256):\n","    ORB = cv2.ORB_create(nfeatures=keypoints)\n","    img = cv2.imread(image)\n","    _, desc = ORB.detectAndCompute(img, None)\n","    return desc\n","\n","# Running\n","# MUCH SLOWER\n","vals = X_train.values.reshape(-1,)\n","read_imgs = list(map(plt.imread, vals))\n","descr = [get_ORB(x) for x in read_imgs]\n","\n","# MUCH FAST\n","vals_cv2 = X_train.values.reshape(-1,)\n","descr_cv2 = list(map(cv2_ORB, vals_cv2))"]},{"cell_type":"markdown","metadata":{"id":"GJehFdyt583b"},"source":["*   What is the size of the feature descriptors? What does each dimension represent in the feature descriptors?"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"bzTspvF96LeC"},"outputs":[{"name":"stdout","output_type":"stream","text":["Single descriptor dimension 2\n","Single descriptor shape (243, 32)\n","Image shape (261, 300, 3)\n"]}],"source":["# solution\n","print(f\"Single descriptor dimension {descr_cv2[0].ndim}\")\n","print(f\"Single descriptor shape {descr_cv2[0].shape}\")\n","print(f\"Image shape {read_imgs[0].shape}\")"]},{"cell_type":"markdown","metadata":{"id":"MNFOjsRj6PGk"},"source":["**Solution**\n","\n","OpenCV's ORB feature extractor uses BRIEF-32, which means that it stores 32 bytes for each giving a length of 256 bit (32*8). In each of the bytes it contains 8 pixel intensity comparisson, as it is explained in the original paper. So each dimensions corresponds to the corresponding pixel intensity comparisson. So what does this tell us? It tells us that ORB, retrieved an array of shape (243, 32), corresponding to its descriptors. These descriptors are what we would use to construct a Codebook, since it tells us \"which features\" are the ones \"decided by ORB\" are the most important. We'd be able to graph these as in previous labs, alongside their keypoints and see which pixels were selected."]},{"cell_type":"markdown","metadata":{"id":"420YQkAzleTQ"},"source":["## Codebook Construction\n","\n","Codewords are nothing but vector representation of similar patches. This codeword produces a codebook similar to a word dictionary. We will create the codebook using K-Means algorithm\n","\n","*   Create a codebook using K-Means with k=number_of_classes*10\n","*   Hint: Use sklearn.cluster.MiniBatchKMeans for K-Means"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["#stacking the descriptors \n","def vStackDescriptors(descriptors_list):\n","    desc = np.array(descriptors_list[0])\n","    for d in descriptors_list[1:]:\n","        desc = np.vstack((desc, d))\n","    return desc\n","\n","vstackdesc = vStackDescriptors(descr_cv2)\n","\n","BATCH_SIZE = len(X_train) // ncl\n","RANDOM_STATE = 42\n","MAX_ITER = 5000\n","# solution\n","kmeans = MiniBatchKMeans(n_clusters=ncl,\n","                         random_state=RANDOM_STATE,\n","                         batch_size=BATCH_SIZE,\n","                         max_iter=MAX_ITER)\n","\n","kmeans = kmeans.fit(vstackdesc)"]},{"cell_type":"markdown","metadata":{"id":"0GAD_JuNpqMt"},"source":["*   Create a histogram using the cluster centers for each image descriptor.\n","    *   Remember the histogram would be of size *n_images x n_clusters*."]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[],"source":["###########################################\n","# Defining variables for the functions \n","LIST_OF_DESCRIPTORS = descr_cv2\n","IMAGES_COUNT = len(X_train)\n","NUMBER_OF_CLUSTERS = ncl\n","############################################\n","\n","def FeatureExtraction(KMEANS, DESCRIPTORS=LIST_OF_DESCRIPTORS, NUMBER_OF_IMAGES=IMAGES_COUNT, CLUSTERS=NUMBER_OF_CLUSTERS,RETURN_SCALED=False):\n","    #creating an empty array of size NUMBER_OF_CLUSTERS x NUMBER_OF_IMAGES\n","    IMG_FEATURES = np.array([np.zeros(CLUSTERS) for images in range(NUMBER_OF_IMAGES)])\n","    # we can loop through the image count \n","    for img in range(NUMBER_OF_IMAGES):\n","        # we then loop through the descriptors for each image\n","        for desc in range(len(DESCRIPTORS[img])):\n","            #now we can extract the specific feature for each of them \n","            FEATURE = DESCRIPTORS[img][desc]\n","            #Reshaping into the corresponding size --> (243, 32) now we have (32,) and needs to go to (1,32)\n","            FEATURE = FEATURE.reshape(1,32)\n","            #Let's predict with the k-Means\n","            pred_idx = KMEANS.predict(FEATURE)\n","            # we add a count for that specific feature --> since we need to make a histogram \n","            IMG_FEATURES[img][pred_idx] +=1\n","    # we need to remove the mean and scale to unit variance \n","    if RETURN_SCALED:\n","        stscale = StandardScaler().fit(IMG_FEATURES)\n","        IMG_FEATURES = stscale.transform(IMG_FEATURES)\n","        return IMG_FEATURES\n","    else: \n","        return IMG_FEATURES\n","\n","def MakeHistogram(IMAGE_FEATURES, CLUSTERS_NUM):\n","    # we need to make both (x, y) scalar \n","    SCALAR_X = np.arange(CLUSTERS_NUM)\n","    # now for y: we sum over the axis=0 and convert it into dtype=int32 to keep a whole number & make it positive \n","    SCALAR_Y = np.array(abs(np.sum(IMAGE_FEATURES, axis=0, dtype=np.int32)))\n","    #make a barplot\n","    plt.bar(SCALAR_X, SCALAR_Y)\n","    #labels\n","    plt.xlabel('INDEX'); plt.ylabel('FREQUENCY'); plt.title(\"Graph 1. Codebook Histogram\")\n","    plt.xticks(SCALAR_X + 0.8, SCALAR_X)\n","    plt.tight_layout()\n","    plt.show()\n","\n","# solution\n","IMG_FEATURES = FeatureExtraction(kmeans, LIST_OF_DESCRIPTORS,IMAGES_COUNT,NUMBER_OF_CLUSTERS,RETURN_SCALED=True)"]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["MakeHistogram(IMG_FEATURES, NUMBER_OF_CLUSTERS)"]},{"cell_type":"markdown","metadata":{"id":"jmRO7dfLjgZa"},"source":["\n","# Creating Classification Model\n","\n","*   The next step is to create a classification model. We will use a C-Support Vector Classification for creating the model.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K7VTBz1Oimtz"},"outputs":[],"source":["from sklearn.svm import SVC\n","from sklearn.model_selection import GridSearchCV"]},{"cell_type":"markdown","metadata":{"id":"lrit95Ud6pUU"},"source":["*   Use GridSearchCV to find the optimal value of C and Gamma."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IjFFpykV-GOI"},"outputs":[],"source":["#Solution\n","def svcParamSelection(X, y, kernel, nfolds):\n","    #Cs = [0.5, 0.1, 0.15, 0.2, 0.3]\n","    Cs2 = list(np.arange(0.01,1.0, 50))\n","    #gammas = [0.1, 0.11, 0.095, 0.105]\n","    gammas_2 = list(np.arange(0.08, 0.15, 50))\n","    param_grid = {'C': Cs2, 'gamma' : gammas_2}\n","    grid_search = GridSearchCV(SVC(kernel=kernel), param_grid, cv=nfolds)\n","    grid_search.fit(X, y)\n","    grid_search.best_params_\n","    return grid_search.best_params_\n","\n","def findSVM(im_features, train_labels, kernel):\n","    features = im_features\n","    if(kernel == \"precomputed\"):\n","      features = np.dot(im_features, im_features.T)\n","    \n","    params = svcParamSelection(features, train_labels, kernel, 5)\n","    C_param, gamma_param = params.get(\"C\"), params.get(\"gamma\")\n","    print(C_param, gamma_param)  \n","    svm = SVC(kernel = kernel, C =  C_param, gamma = gamma_param)\n","    svm.fit(features, train_labels)\n","    return svm"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["svm = findSVM(im_features, y_train.values.ravel(),'precomputed')"]},{"cell_type":"markdown","metadata":{"id":"eqThTmO5j1-p"},"source":["# Testing the Classification Model\n","\n","*   Extract descriptors using ORB for the test split\n","*   Use the previously trained k-means to generate the histogram\n","*   Use the classifier to predict the label\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x2Gzbww9e0pP"},"outputs":[],"source":["# solution\n","\n","https://github.com/gurkandemir/Bag-of-Visual-Words/blob/df6080dec5fe227ffb1d7e47403b58401891882e/Code%20Files/BoW.py#L73\n","\n","\n","https://machinelearningknowledge.ai/image-classification-using-bag-of-visual-words-model/\n"]},{"cell_type":"markdown","metadata":{"id":"gGyQUtU3lAEz"},"source":["*   Calculate the accuracy score for the classification model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PszxSB0Ek_Lt"},"outputs":[],"source":["# solution\n","\n"]},{"cell_type":"markdown","metadata":{"id":"drlq-5AM615_"},"source":["*   Generate the confusion matrix for the classification model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NpqXVYrw61OG"},"outputs":[],"source":["# solution\n","\n"]},{"cell_type":"markdown","metadata":{"id":"7TN4rRra9yv_"},"source":["*   Why do we use Clustering to create the codebook? \n","*   What are the other techniques that can be used to create the codebook?"]},{"cell_type":"markdown","metadata":{"id":"Ri9kU3wa3Rei"},"source":["**Solution**\n","\n","*(Double-click or enter to edit)*\n","\n","..."]},{"cell_type":"markdown","metadata":{"id":"ll0j8G-oIaHd"},"source":["*   Will adding more keypoints increase the performanc of the algorithm?"]},{"cell_type":"markdown","metadata":{"id":"ka3z1sJVInS5"},"source":["**Solution**\n","\n","*(Double-click or enter to edit)*\n","\n","..."]},{"cell_type":"markdown","metadata":{"id":"K-8E3dBw8Zoa"},"source":["# Extracting features from Deep Network\n","\n","It is quite possible to extract features (similar to SIFT or ORB) from different layers of deep network.\n","\n","*   Load ResNet50 model with imagenet weights and check the summary of the model\n","*   Create a model to extract features from the 'avg_pool' layer.\n","*   Extract features from the layer for all the train images."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EJ83bPO3mO16"},"outputs":[],"source":["# solution\n","\n"]},{"cell_type":"markdown","metadata":{"id":"HFN1GjP-7IJ4"},"source":["*   What is the size of the feature descriptors?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GCbFj-8fieht"},"outputs":[],"source":["# solution\n","\n"]},{"cell_type":"markdown","metadata":{"id":"GkEprqtK87q2"},"source":["*   Create codebook using the extracted features"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5crz4gBz9CQF"},"outputs":[],"source":["# solution\n","\n"]},{"cell_type":"markdown","metadata":{"id":"K_RB2vPl9CzB"},"source":["*   Train SVM classifier using the codebook"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5oKk_Wzz9HLf"},"outputs":[],"source":["# solution\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ym0XesGL9Hrc"},"source":["*   Evaluate the test set using the above method"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NM6LIynq9Ma1"},"outputs":[],"source":["# solution\n","\n"]},{"cell_type":"markdown","metadata":{"id":"d-OnKf-ti_vy"},"source":["*   Calculate the accuracy score and confusion matrix for the classification model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"upqdRQUoGC94"},"outputs":[],"source":["# solution\n","\n"]},{"cell_type":"markdown","metadata":{"id":"eafGx0Hv9M6p"},"source":["*   Compare the performance of both the BoVW models. Which model works better and why?"]},{"cell_type":"markdown","metadata":{"id":"U9SOuiKwiXkr"},"source":["**Solution**\n","\n","*(Double-click or enter to edit)*\n","\n","..."]},{"cell_type":"markdown","metadata":{"id":"8BuiFGxPjDb1"},"source":["*   Can the performance of pre-trained model increased further? If so, how?"]},{"cell_type":"markdown","metadata":{"id":"0kuJnOb9jE9r"},"source":["**Solution**\n","\n","*(Double-click or enter to edit)*\n","\n","..."]},{"cell_type":"markdown","metadata":{"id":"jQlPanaIIMKV"},"source":["*   What happens if the test image does not belong to any of the trained classes?"]},{"cell_type":"markdown","metadata":{"id":"5UEnEFDdISFJ"},"source":["**Solution**\n","\n","*(Double-click or enter to edit)*\n","\n","..."]},{"cell_type":"markdown","metadata":{"id":"Z-sxoswiJGTQ"},"source":["*   Combine the features extracted using ORB and Deep Neural Network.\n","*   Create a codebook with the combined features\n","*   Train a SVM classifier using the generated codebook and evaluate the performance using accuracy and confusion matrix."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u5Xgv3caJf6X"},"outputs":[],"source":["# solution\n","\n"]},{"cell_type":"markdown","metadata":{"id":"i2iBPUZTJhju"},"source":["*   Do the combined features increase the performance of the classifier?"]},{"cell_type":"markdown","metadata":{"id":"ZYG_4SReJg2A"},"source":["**Solution**\n","\n","*(Double-click or enter to edit)*\n","\n","..."]},{"cell_type":"markdown","metadata":{"id":"DjL0oQCumkrV"},"source":["## t-distributed Stochastic Neighbor Embedding (Optional).\n","\n","In order to visualize the features of a higher dimension data, t-SNE is used. t-SNE converts the affinities of the data points to probabilities. It recreates the probability distribution in a low-dimensional space. It is very helpful in visualizing features of different layers in a neural network.\n","\n","You can find more information about t-SNE [here](https://scikit-learn.org/stable/modules/manifold.html#t-distributed-stochastic-neighbor-embedding-t-sne)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6ahIG1fulhW9"},"outputs":[],"source":["from sklearn.manifold import TSNE\n","\n","model = TSNE(n_components=2, random_state=0)\n","\n","np.set_printoptions(suppress=True)\n","\n","low_embedding = model.fit_transform(dictionary) \n","\n","plt.figure(figsize=(20,10))\n","plt.scatter(low_embedding[:, 0], low_embedding[:, 1], c=y_train)\n","plt.title(\"TSNE visualization\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"3_HR5GjFpjik"},"source":["*   What do you infer from the t-SNE plot?"]},{"cell_type":"markdown","metadata":{"id":"ueY9rvGBrVIc"},"source":["**Solution**\n","\n","*(Double-click or enter to edit)*\n","\n","..."]},{"cell_type":"markdown","metadata":{"id":"NnN_t5Me7N5O"},"source":["\n","---\n","\n","## **End of P4_2: Image Classification using Bag of Visual Words**\n","Deadline for P4_2 submission in CampusVirtual is: **Monday, the 6th of December, 2021**"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"p4_2_image_classification_using_BoVW.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"}},"nbformat":4,"nbformat_minor":0}
